{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetune ruGPT3 as COVID-19 FAQ",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57zPRPUtn9lV"
      },
      "source": [
        "## README"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCfTA8eOmXHS"
      },
      "source": [
        "Please check your Colab GPU. You should have at least 16GB RAM to fine tune the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyURC4d5HWnC"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK10D3MSpYty"
      },
      "source": [
        "## INSTALL TRANSFORMERS / CUDA / APEX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPqtVgbkeTx7"
      },
      "source": [
        "!pip3 install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkjTWefecLc"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sberbank-ai/ru-gpts/master/pretrain_transformers.py\n",
        "!wget https://raw.githubusercontent.com/sberbank-ai/ru-gpts/master/generate_transformers.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtAeHbhbTnzO"
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udZ7AiMWTpD9"
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP7YAlDPqknI"
      },
      "source": [
        "## GET DATA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dPSLF5CkraZ"
      },
      "source": [
        "!rm -rf ruGPT3\n",
        "!rm -rf sample_data\n",
        "!git clone https://github.com/gotzmann/ruGPT3.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2DCSV4iXWXT"
      },
      "source": [
        "import glob\n",
        "datasets = glob.glob(\"ruGPT3/datasets/*\")\n",
        "with open('corpus.txt', 'w') as outfile:\n",
        "    for name in datasets:\n",
        "        with open(name) as infile:\n",
        "            outfile.write(infile.read())\n",
        "            outfile.write(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDYi1TVTrtkO"
      },
      "source": [
        "## PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl1kJFAeahRV"
      },
      "source": [
        "data = open('corpus.txt', 'r').read()\n",
        "data = data.split('\\n\\n')\n",
        "\n",
        "# Do we need some preprocessing here?\n",
        "\n",
        "# data = data.replace('COVID-19', 'коронавирус')\n",
        "# data = data.replace('COVID', 'коронавирус')\n",
        "\n",
        "# Do split the whole dataset to train / validate portions?\n",
        "\n",
        "# import numpy as np\n",
        "# import random\n",
        "\n",
        "# random.seed(1980)\n",
        "# np.random.seed(1980)\n",
        "\n",
        "# val_ind = random.sample(range(len(data)), int(len(data) / 5))\n",
        "# train = [data[i] for i in range(len(data)) if i not in val_ind][:len(data)]\n",
        "# valid = [data[i] for i in range(len(data)) if i in val_ind]\n",
        "# train = [str.replace('\\n', ' ') for str in train]\n",
        "# valid = [str.replace('\\n', ' ') for str in valid]\n",
        "\n",
        "# Or just train on the whole data?\n",
        "\n",
        "train = [str.replace('\\n', ' ') for str in data]\n",
        "valid = [str.replace('\\n', ' ') for str in data]\n",
        "\n",
        "# Do we need JSON for GPT3 Large and plaintext for Medium / Small?\n",
        "\n",
        "# train = [str.replace('\"', '\\\\\"') for str in train]\n",
        "# valid = [str.replace('\"', '\\\"') for str in valid]\n",
        "\n",
        "# train = ['{ \"text\" : \"' + str + '\" }' for str in train]\n",
        "# valid = ['{ \"text\" : \"' + str + '\" }' for str in valid]\n",
        "\n",
        "with open(\"train.data\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(train))\n",
        "    \n",
        "with open(\"valid.data\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(valid)) \n",
        "\n",
        "len(train), len(valid)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NitGcEKPsDQE"
      },
      "source": [
        "## FINE-TUNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vL07XFvsBBU"
      },
      "source": [
        "# To fit all the data in Collab GPU, we use Medium model with block size of 1024\n",
        "# If your GPU has more than 16Gb, go better with Large and 2048 blocks\n",
        "\n",
        "!python pretrain_transformers.py \\\n",
        "    --output_dir=model \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=sberbank-ai/rugpt3medium_based_on_gpt2 \\\n",
        "    --do_train \\\n",
        "    --train_data_file=train.data \\\n",
        "    --do_eval \\\n",
        "    --eval_data_file=valid.data \\\n",
        "    --fp16 \\\n",
        "    --per_gpu_train_batch_size 1 \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --block_size 1024 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --line_by_line "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2N6ylGPt1F5"
      },
      "source": [
        "## 42 :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRlAAsIbsHdf"
      },
      "source": [
        "!python generate_transformers.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=model \\\n",
        "    --k=50 \\\n",
        "    --p=0.95 \\\n",
        "    --length=100 \\\n",
        "    --temperature=0.75 \\\n",
        "    --num_return_sequences=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNV6K9s7pYeW"
      },
      "source": [
        "## EXAMPLES\n",
        "\n",
        "Q: Что такое коронавирус? A:\n",
        "\n",
        "Q: Каковы первые симптомы коронавируса? A:\n",
        "\n",
        "Q: Что лучше защищает от коронавируса: маска или респиратор?\n",
        "\n",
        "Q: Какие лекарственные препараты назначают пациентам с коронавирусом? A:"
      ]
    }
  ]
}